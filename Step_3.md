Tuyá»‡t vá»i\! Viá»‡c Phase 1 (Háº¡ táº§ng Kafka) vÃ  Phase 2 (Thu tháº­p dá»¯ liá»‡u) Ä‘Ã£ vÆ°á»£t qua bÃ i test lÃ  cá»™t má»‘c quan trá»ng. Há»‡ thá»‘ng cá»§a báº¡n hiá»‡n Ä‘Ã£ cÃ³ "Máº¡ch mÃ¡u" (Kafka) vÃ  "Tim" (Producer).

BÃ¢y giá» chÃºng ta sáº½ xÃ¢y dá»±ng "Bá»™ nÃ£o" (Brain) trong **Phase 3: Machine Learning & Real-time Prediction**.

ÄÃ¢y lÃ  giai Ä‘oáº¡n phá»©c táº¡p nháº¥t vÃ¬ nÃ³ chá»©a Ä‘á»±ng logic toÃ¡n há»c. Má»¥c tiÃªu lÃ  thay tháº¿ cÃ¡c thuáº­t toÃ¡n Linear Regression/KNN Ä‘Æ¡n giáº£n cÅ© báº±ng bá»™ 3 máº¡nh máº½ hÆ¡n: **Random Forest, SVM, Logistic Regression**, Ä‘á»“ng thá»i kháº¯c phá»¥c váº¥n Ä‘á» *Data Leakage* (rÃ² rá»‰ dá»¯ liá»‡u) vÃ  *Cold Start* (thiáº¿u dá»¯ liá»‡u Ä‘áº§u vÃ o).

-----

### ðŸ“‹ Má»¤C TIÃŠU PHASE 3

1.  **Feature Engineering Ä‘á»“ng bá»™:** Äáº£m báº£o cÃ¡ch tÃ­nh chá»‰ bÃ¡o (RSI, MACD, MA) lÃºc Training vÃ  lÃºc cháº¡y Real-time lÃ  *giá»‘ng há»‡t nhau* (trÃ¡nh sai sá»‘ logic).
2.  **Huáº¥n luyá»‡n (Training):** Táº£i dá»¯ liá»‡u lá»‹ch sá»­ vÃ  train 3 model má»›i, lÆ°u ra file `.joblib`.
3.  **Dá»± Ä‘oÃ¡n Real-time (Consumer):** Láº¯ng nghe dá»¯ liá»‡u tá»«ng giÃ¢y tá»« Kafka -\> TÃ­ch lÅ©y Ä‘á»§ náº¿n -\> Dá»± Ä‘oÃ¡n -\> Báº¯n tÃ­n hiá»‡u ra Kafka.

-----

### ðŸ› ï¸ BÆ¯á»šC 1: CÃ€I Äáº¶T THÆ¯ VIá»†N ML

Cáº­p nháº­t `requirements.txt` Ä‘á»ƒ thÃªm cÃ¡c thÆ° viá»‡n toÃ¡n há»c vÃ  ká»¹ thuáº­t:

```text
scikit-learn==1.3.0
pandas_ta==0.3.14b  # ThÆ° viá»‡n tÃ­nh chá»‰ bÃ¡o ká»¹ thuáº­t chuáº©n xÃ¡c
joblib==1.3.2
```

Cháº¡y lá»‡nh: `pip install -r requirements.txt`

-----

### ðŸ§  BÆ¯á»šC 2: Táº O MODULE FEATURE ENGINEERING (QUAN TRá»ŒNG NHáº¤T)

**Váº¥n Ä‘á»:** Trong dá»± Ã¡n cÅ©, code xá»­ lÃ½ dá»¯ liá»‡u náº±m ráº£i rÃ¡c.
**Giáº£i phÃ¡p:** Táº¡o má»™t file dÃ¹ng chung `app/ml/feature_engineering.py`. File nÃ y sáº½ Ä‘Æ°á»£c gá»i bá»Ÿi cáº£ *script training* vÃ  *consumer real-time*.

```python
import pandas as pd
import pandas_ta as ta

def calculate_features(df: pd.DataFrame):
    """
    HÃ m tÃ­nh toÃ¡n chá»‰ bÃ¡o ká»¹ thuáº­t.
    Input: DataFrame chá»©a OHLCV (Open, High, Low, Close, Volume)
    Output: DataFrame Ä‘Ã£ cÃ³ thÃªm cÃ¡c cá»™t features (RSI, SMA, v.v.)
    """
    df = df.copy()
    
    # 1. Trend Indicators
    df['SMA_10'] = ta.sma(df['close'], length=10)
    df['SMA_50'] = ta.sma(df['close'], length=50)
    
    # 2. Momentum Indicators
    df['RSI_14'] = ta.rsi(df['close'], length=14)
    
    # 3. Volatility (Biáº¿n Ä‘á»™ng)
    # Bollinger Bands
    bb = ta.bbands(df['close'], length=20)
    if bb is not None:
        df['BB_UPPER'] = bb['BBU_20_2.0']
        df['BB_LOWER'] = bb['BBL_20_2.0']
    
    # 4. Target (Chá»‰ dÃ¹ng cho training, Realtime sáº½ bá» qua dÃ²ng nÃ y)
    # Target: 1 náº¿u giÃ¡ Ä‘Ã³ng cá»­a sau 1 náº¿n tÄƒng, 0 náº¿u giáº£m
    df['target'] = (df['close'].shift(-1) > df['close']).astype(int)
    
    # XÃ³a cÃ¡c dÃ²ng NaN do tÃ­nh toÃ¡n chá»‰ bÃ¡o (vÃ­ dá»¥ 50 dÃ²ng Ä‘áº§u tiÃªn cá»§a SMA_50)
    df.dropna(inplace=True)
    
    return df
```

-----

### ðŸŽ“ BÆ¯á»šC 3: HUáº¤N LUYá»†N MÃ” HÃŒNH (TRAINING)

ChÃºng ta sáº½ viáº¿t script tá»± Ä‘á»™ng táº£i dá»¯ liá»‡u lá»‹ch sá»­ tá»« Binance vá» Ä‘á»ƒ train, thay vÃ¬ phá»¥ thuá»™c vÃ o file CSV cÅ©.

**Táº¡o file:** `app/ml/train_models.py`

```python
import ccxt
import pandas as pd
import joblib
import os
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from feature_engineering import calculate_features

# Táº¡o thÆ° má»¥c lÆ°u model náº¿u chÆ°a cÃ³
os.makedirs('app/ml/models', exist_ok=True)

def fetch_historical_data(symbol='BTC/USDT', limit=1000):
    print(f"ðŸ“¥ Äang táº£i {limit} náº¿n quÃ¡ khá»© cá»§a {symbol}...")
    exchange = ccxt.binance()
    ohlcv = exchange.fetch_ohlcv(symbol, timeframe='1m', limit=limit)
    df = pd.DataFrame(ohlcv, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])
    return df

def train():
    # 1. Chuáº©n bá»‹ dá»¯ liá»‡u
    df = fetch_historical_data()
    df = calculate_features(df)
    
    # Chá»n Features (X) vÃ  Target (y)
    features = ['close', 'volume', 'SMA_10', 'SMA_50', 'RSI_14']
    X = df[features]
    y = df['target']
    
    # Chia táº­p Train/Test
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)
    
    print(f"ðŸ“Š Dá»¯ liá»‡u training: {len(X_train)} máº«u")

    # 2. Train Random Forest (Model chÃ­nh báº¯t Trend)
    print("ðŸ§  Training Random Forest...")
    rf = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)
    rf.fit(X_train, y_train)
    print(f"   Accuracy RF: {accuracy_score(y_test, rf.predict(X_test)):.2f}")
    
    # 3. Train SVM (PhÃ¢n loáº¡i biÃªn Ä‘á»™ khÃ³)
    print("ðŸ§  Training SVM...")
    svm = SVC(probability=True, kernel='rbf') # probability=True Ä‘á»ƒ láº¥y Ä‘á»™ tin cáº­y
    svm.fit(X_train, y_train)
    print(f"   Accuracy SVM: {accuracy_score(y_test, svm.predict(X_test)):.2f}")

    # 4. Train Logistic Regression (XÃ¡c suáº¥t ná»n)
    print("ðŸ§  Training Logistic Regression...")
    lr = LogisticRegression()
    lr.fit(X_train, y_train)
    print(f"   Accuracy LR: {accuracy_score(y_test, lr.predict(X_test)):.2f}")

    # 5. LÆ°u models
    joblib.dump(rf, 'app/ml/models/rf_model.joblib')
    joblib.dump(svm, 'app/ml/models/svm_model.joblib')
    joblib.dump(lr, 'app/ml/models/lr_model.joblib')
    print("âœ… ÄÃ£ lÆ°u 3 models vÃ o thÆ° má»¥c app/ml/models/")

if __name__ == "__main__":
    train()
```

> **HÃ nh Ä‘á»™ng:** Cháº¡y `python app/ml/train_models.py` Ä‘á»ƒ táº¡o ra 3 file model `.joblib`.

-----

### ðŸ”® BÆ¯á»šC 4: XÃ‚Y Dá»°NG ML CONSUMER (REAL-TIME PREDICTOR)

ÄÃ¢y lÃ  pháº§n khÃ³ nháº¥t: Consumer nháº­n tá»«ng náº¿n rá»i ráº¡c, nhÆ°ng ML cáº§n má»™t chuá»—i náº¿n (Series) Ä‘á»ƒ tÃ­nh SMA\_50.
**Giáº£i phÃ¡p:** DÃ¹ng má»™t bá»™ nhá»› Ä‘á»‡m (Buffer) Ä‘á»ƒ lÆ°u 50-60 náº¿n gáº§n nháº¥t.

**Táº¡o file:** `app/consumers/ml_predictor.py`

```python
import json
import os
import joblib
import pandas as pd
import numpy as np
from confluent_kafka import Consumer, Producer
from dotenv import load_dotenv

# Import hÃ m tÃ­nh feature dÃ¹ng chung (Ä‘á»ƒ logic giá»‘ng há»‡t lÃºc train)
import sys
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'ml'))
from feature_engineering import calculate_features

load_dotenv()

class MLPredictor:
    def __init__(self):
        # Config Kafka
        self.consumer = Consumer({
            'bootstrap.servers': os.getenv('KAFKA_BOOTSTRAP_SERVERS', 'localhost:9092'),
            'group.id': 'ml_predictor_group',
            'auto.offset.reset': 'latest'
        })
        self.producer = Producer({'bootstrap.servers': os.getenv('KAFKA_BOOTSTRAP_SERVERS')})
        
        self.consumer.subscribe(['crypto.market_data'])
        self.produce_topic = 'crypto.ml_signals'

        # Load Models
        print("â³ Loading models...")
        self.rf = joblib.load('app/ml/models/rf_model.joblib')
        self.svm = joblib.load('app/ml/models/svm_model.joblib')
        self.lr = joblib.load('app/ml/models/lr_model.joblib')
        
        # Buffer: Cáº§n Ã­t nháº¥t 50 náº¿n Ä‘á»ƒ tÃ­nh SMA_50
        self.data_buffer = [] 
        self.min_required_data = 52 

    def predict(self, current_data):
        # 1. ThÃªm dá»¯ liá»‡u má»›i vÃ o buffer
        self.data_buffer.append(current_data)
        
        # Giá»¯ buffer khÃ´ng quÃ¡ dÃ i (chá»‰ cáº§n 100 náº¿n gáº§n nháº¥t lÃ  Ä‘á»§ tÃ­nh toÃ¡n)
        if len(self.data_buffer) > 100:
            self.data_buffer.pop(0)
            
        # 2. Kiá»ƒm tra Cold Start (ChÆ°a Ä‘á»§ dá»¯ liá»‡u thÃ¬ chÆ°a dá»± Ä‘oÃ¡n)
        if len(self.data_buffer) < self.min_required_data:
            print(f"â³ Äang tÃ­ch lÅ©y dá»¯ liá»‡u: {len(self.data_buffer)}/{self.min_required_data}")
            return

        # 3. Táº¡o DataFrame tá»« buffer Ä‘á»ƒ tÃ­nh feature
        df = pd.DataFrame(self.data_buffer)
        df = calculate_features(df) # HÃ m nÃ y sáº½ tráº£ vá» DataFrame Ä‘Ã£ cÃ³ cá»™t SMA, RSI...
        
        # Láº¥y dÃ²ng cuá»‘i cÃ¹ng (má»›i nháº¥t) Ä‘á»ƒ dá»± Ä‘oÃ¡n
        last_row = df.iloc[[-1]][['close', 'volume', 'SMA_10', 'SMA_50', 'RSI_14']]
        
        # 4. Dá»± Ä‘oÃ¡n báº±ng 3 models
        rf_pred = self.rf.predict(last_row)[0]
        svm_pred = self.svm.predict(last_row)[0]
        lr_prob = self.lr.predict_proba(last_row)[0][1] # XÃ¡c suáº¥t tÄƒng giÃ¡
        
        # 5. Tá»•ng há»£p tÃ­n hiá»‡u (Ensemble Logic)
        signal = "NEUTRAL"
        if rf_pred == 1 and svm_pred == 1 and lr_prob > 0.6:
            signal = "BUY"
        elif rf_pred == 0 and svm_pred == 0 and lr_prob < 0.4:
            signal = "SELL"
            
        # 6. Gá»­i káº¿t quáº£ vÃ o Kafka
        result = {
            "timestamp": current_data['timestamp'],
            "price": current_data['close'],
            "signal": signal,
            "details": {
                "rf": int(rf_pred),
                "svm": int(svm_pred),
                "confidence": float(round(lr_prob, 4))
            }
        }
        
        self.producer.produce(self.produce_topic, json.dumps(result).encode('utf-8'))
        self.producer.flush()
        print(f"ðŸ”® Prediction: {signal} | Price: {current_data['close']} | Conf: {lr_prob:.2f}")

    def start(self):
        print("ðŸš€ ML Predictor Service Started...")
        try:
            while True:
                msg = self.consumer.poll(1.0)
                if msg is None: continue
                
                data = json.loads(msg.value().decode('utf-8'))
                self.predict(data)
                
        except KeyboardInterrupt:
            self.consumer.close()

if __name__ == "__main__":
    service = MLPredictor()
    service.start()
```

-----

### âœ… BÆ¯á»šC 5: KIá»‚M TRA TOÃ€N Bá»˜ Há»† THá»NG (INTEGRATION TEST)

BÃ¢y giá» báº¡n sáº½ cháº¡y thá»­ cáº£ 3 Phase káº¿t há»£p láº¡i. HÃ£y má»Ÿ 3 cá»­a sá»• Terminal (hoáº·c tab).

**Terminal 1: Háº¡ táº§ng (Phase 1)**

```bash
docker-compose up -d
```

*Check:* Äáº£m báº£o Kafka vÃ  Zookeeper Ä‘ang cháº¡y.

**Terminal 2: Producer (Phase 2)**

```bash
python app/producers/market_data_producer.py
```

*Check:* Tháº¥y log `ðŸ“¡ Sent: BTCUSDT...`

**Terminal 3: ML Predictor (Phase 3)**
Äáº§u tiÃªn, hÃ£y nhá»› cháº¡y train model trÆ°á»›c (chá»‰ lÃ m 1 láº§n):

```bash
python app/ml/train_models.py
```

Sau Ä‘Ã³ cháº¡y Service dá»± Ä‘oÃ¡n:

```bash
python app/consumers/ml_predictor.py
```

-----

### ðŸ”Ž QUAN SÃT Káº¾T QUáº¢ TEST

Khi Terminal 3 cháº¡y:

1.  **LÃºc Ä‘áº§u:** Báº¡n sáº½ tháº¥y thÃ´ng bÃ¡o `â³ Äang tÃ­ch lÅ©y dá»¯ liá»‡u: 1/52`, `2/52`... Do cáº§n Ä‘á»§ 50 náº¿n má»›i tÃ­nh Ä‘Æ°á»£c SMA\_50.
2.  **Sau khoáº£ng vÃ i phÃºt:** Khi Ä‘á»§ dá»¯ liá»‡u, báº¡n sáº½ tháº¥y:
    ```text
    ðŸ”® Prediction: NEUTRAL | Price: 68120 | Conf: 0.51
    ðŸ”® Prediction: BUY | Price: 68150 | Conf: 0.75
    ```

**Debug:** Báº¡n cÃ³ thá»ƒ má»Ÿ thÃªm Terminal 4 cháº¡y file `debug_kafka.py` (á»Ÿ Phase 2) nhÆ°ng sá»­a topic thÃ nh `crypto.ml_signals` Ä‘á»ƒ xem Ä‘áº§u ra JSON cuá»‘i cÃ¹ng mÃ  Dashboard sáº½ nháº­n Ä‘Æ°á»£c.

### ðŸ’¡ Táº I SAO CÃCH NÃ€Y Tá»I Æ¯U?

  * **Ensemble Learning:** Thay vÃ¬ tin 1 model, ta káº¿t há»£p RF (Trend), SVM (Boundary) vÃ  LR (Probability). Chá»‰ khi cáº£ 3 Ä‘á»“ng thuáº­n (`BUY`), rá»§i ro má»›i tháº¥p nháº¥t.
  * **TrÃ¡nh Data Leakage:** Viá»‡c tÃ¡ch file `feature_engineering.py` Ä‘áº£m báº£o logic tÃ­nh toÃ¡n lÃ  nháº¥t quÃ¡n tuyá»‡t Ä‘á»‘i.
  * **Kháº¯c phá»¥c Cold Start:** CÆ¡ cháº¿ Buffer Ä‘áº£m báº£o khÃ´ng bá»‹ lá»—i tÃ­nh toÃ¡n khi má»›i khá»Ÿi Ä‘á»™ng há»‡ thá»‘ng.

Phase 3 hoÃ n táº¥t sáº½ cho báº¡n dÃ²ng dá»¯ liá»‡u `crypto.ml_signals` cá»±c ká»³ giÃ¡ trá»‹. Phase tiáº¿p theo chÃºng ta chá»‰ viá»‡c hiá»ƒn thá»‹ nÃ³ lÃªn Dashboard vÃ  khá»›p lá»‡nh áº£o\!